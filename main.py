import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
import threading
import time
import pandas as pd
import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# å›ºå®šè¨­å®š
TARGET_URL = "https://www.indiegogo.com/en/projects/search?SortType=MostPopular&Source=Filtered"
DEFAULT_PAUSE_TIME = 3.0
DEFAULT_MAX_SCROLLS = 50

class ScraperApp(tk.Tk):
    
    def __init__(self):
        super().__init__()
        self.title("Indiegogo Scraper (GUI)")
        self.geometry("600x450") 
        
        self.is_running = False
        
        self.create_widgets()

    def create_widgets(self):
        """UIéƒ¨å“ã®ä½œæˆã¨é…ç½®"""
        
        settings_frame = ttk.LabelFrame(self, text="è¨­å®š", padding="10 10 10 10")
        settings_frame.pack(pady=10, padx=10, fill='x')

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¾…æ©Ÿæ™‚é–“ (ç§’)
        self.pause_time_frame = ttk.Frame(settings_frame)
        self.pause_time_frame.pack(pady=5, anchor='w')
        ttk.Label(self.pause_time_frame, text="ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¾…æ©Ÿæ™‚é–“ (ç§’):").pack(side=tk.LEFT, padx=5)
        
        self.pause_time_var = tk.DoubleVar(value=DEFAULT_PAUSE_TIME)
        self.pause_time_entry = ttk.Spinbox(
            self.pause_time_frame, 
            from_=1.0, to=60.0, increment=0.5, 
            textvariable=self.pause_time_var, width=5, 
            justify=tk.RIGHT
        )
        self.pause_time_entry.pack(side=tk.LEFT)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å›æ•°ä¸Šé™
        self.max_scrolls_frame = ttk.Frame(settings_frame)
        self.max_scrolls_frame.pack(pady=5, anchor='w')
        ttk.Label(self.max_scrolls_frame, text="ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å›æ•°ä¸Šé™:").pack(side=tk.LEFT, padx=5)
        
        self.max_scrolls_var = tk.IntVar(value=DEFAULT_MAX_SCROLLS) 
        self.max_scrolls_entry = ttk.Spinbox(
            self.max_scrolls_frame, 
            from_=1, to=1000, increment=1, 
            textvariable=self.max_scrolls_var, width=5, 
            justify=tk.RIGHT
        )
        self.max_scrolls_entry.pack(side=tk.LEFT)
        
        # --- å®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨ãƒœã‚¿ãƒ³ ---
        self.status_label = ttk.Label(self, text="æº–å‚™å®Œäº†", font=("Arial", 12, "bold"))
        self.status_label.pack(pady=5)

        self.start_button = ttk.Button(self, text="ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", command=self.start_scraping_thread)
        self.start_button.pack(pady=5)
        
        # --- ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢ ---
        self.log_text = scrolledtext.ScrolledText(self, width=70, height=10, state=tk.DISABLED)
        self.log_text.pack(pady=10, padx=10, fill='both', expand=True)

    def update_status(self, message):
        """GUIã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ©ãƒ™ãƒ«ã¨ãƒ­ã‚°ã‚’æ›´æ–°ã™ã‚‹ (ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•)"""
        self.status_label.config(text=message)
        self.log_text.config(state=tk.NORMAL)
        self.log_text.insert(tk.END, f"{time.strftime('[%H:%M:%S]')} {message}\n")
        self.log_text.see(tk.END)
        self.log_text.config(state=tk.DISABLED)

    def start_scraping_thread(self):
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§é–‹å§‹ã™ã‚‹å‰ã«ã€è¨­å®šã‚’ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹"""
        if self.is_running:
            self.update_status("âš ï¸ æ—¢ã«å®Ÿè¡Œä¸­ã§ã™ã€‚")
            return

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            scroll_pause_time = float(self.pause_time_var.get())
            max_scrolls = int(self.max_scrolls_var.get())
        except ValueError:
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "å¾…æ©Ÿæ™‚é–“ã¨ãƒ«ãƒ¼ãƒ—æ•°ã«ã¯æ•°å€¤ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            self.update_status("ğŸ”´ ã‚¨ãƒ©ãƒ¼: è¨­å®šå€¤ãŒç„¡åŠ¹ã§ã™ã€‚")
            return

        if scroll_pause_time < 1.0:
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¾…æ©Ÿæ™‚é–“ã¯æœ€å°1.0ç§’ã§ã™ã€‚")
            self.update_status("ğŸ”´ ã‚¨ãƒ©ãƒ¼: è¨­å®šå€¤ãŒç„¡åŠ¹ã§ã™ã€‚")
            return
        
        if max_scrolls < 1:
            messagebox.showerror("å…¥åŠ›ã‚¨ãƒ©ãƒ¼", "ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å›æ•°ä¸Šé™ã¯æœ€å°1å›ã§ã™ã€‚")
            self.update_status("ğŸ”´ ã‚¨ãƒ©ãƒ¼: è¨­å®šå€¤ãŒç„¡åŠ¹ã§ã™ã€‚")
            return

        self.is_running = True
        self.start_button.config(state=tk.DISABLED)
        self.update_status("â–¶ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸ...")
        
        self.scraper_thread = threading.Thread(
            target=self.run_scraper, 
            args=(scroll_pause_time, max_scrolls)
        )
        self.scraper_thread.start()

    def run_scraper(self, SCROLL_PAUSE_TIME, MAX_SCROLLS):
        """Seleniumã‚’ä½¿ã£ãŸå®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç† (åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ)"""
        driver = None
        try:
            self.update_status(" Chrome WebDriverã‚’åˆæœŸåŒ–ä¸­...")
            driver = self.initialize_driver()
            
            self.update_status(f" ã‚¿ãƒ¼ã‚²ãƒƒãƒˆURLã¸ç§»å‹•ä¸­: {TARGET_URL}")
            driver.get(TARGET_URL)
            time.sleep(SCROLL_PAUSE_TIME) 
            
            self.scroll_to_load_all_content(driver, SCROLL_PAUSE_TIME, MAX_SCROLLS)
            
            self.update_status(" èª­ã¿è¾¼ã‚“ã HTMLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
            projects_data = self.parse_and_extract(driver)
            
            if projects_data:
                # â˜… process_and_save ã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ¸¡ã™ã‚ˆã†ã«å¤‰æ›´
                self.process_and_save(projects_data) 
            else:
                self.update_status("âŒ æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã§ã—ãŸã€‚")

        except Exception as e:
            self.update_status(f"ğŸ”´ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print(f"Exception: {e}") 

        finally:
            if driver:
                driver.quit()
                self.update_status("âœ… å‡¦ç†å®Œäº†ã€‚WebDriverã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚")
            
            self.is_running = False
            self.start_button.config(state=tk.NORMAL)
            
    # --- Selenium Helper Functions ---
    def initialize_driver(self):
        """Chromeãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’åˆæœŸåŒ–ã—ã€WebDriverã‚’è¿”ã™"""
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")  
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--disable-gpu")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        options.add_argument("--no-sandbox")
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    
    def scroll_to_load_all_content(self, driver, SCROLL_PAUSE_TIME, MAX_SCROLLS):
        """æœ€åˆã«Load moreãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãã®å¾Œãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦å…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã‚€"""
        self.update_status("--- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„èª­ã¿è¾¼ã¿å‡¦ç†é–‹å§‹ ---")
        try:
            self.update_status(" 'Load more' ãƒœã‚¿ãƒ³ã‚’æ¤œç´¢ä¸­...")
            load_more_button = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//button[span[contains(text(), 'Load more')]]"))
            )
            load_more_button.click()
            self.update_status(" 'Load more' ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
            time.sleep(SCROLL_PAUSE_TIME) 
        except Exception:
            self.update_status(" 'Load more' ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç„¡é™ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã«é€²ã¿ã¾ã™ã€‚")

        self.update_status("ç„¡é™ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã§è¿½åŠ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        load_count = 0
        
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(SCROLL_PAUSE_TIME)
            new_height = driver.execute_script("return document.body.scrollHeight")
            
            if new_height == last_height or load_count >= MAX_SCROLLS:
                self.update_status(f"ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«çµ‚äº†ã€‚åˆè¨ˆ {load_count} å›ã®è¿½åŠ èª­ã¿è¾¼ã¿ã‚’è¡Œã„ã¾ã—ãŸã€‚")
                break
            
            last_height = new_height
            load_count += 1
            self.update_status(f"ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« {load_count}/{MAX_SCROLLS} å›ç›®...")

    def parse_and_extract(self, driver):
        """WebDriverã§å–å¾—ã—ãŸHTMLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹"""
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        project_cards = soup.select('div[data-qa^="search-result-project:"]')
        self.update_status(f" HTMLã‹ã‚‰ {len(project_cards)} ä»¶ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡ºã€‚")
        
        extracted_data = []
        for card in project_cards:
            name_element = card.select_one('h3[data-qa="project-card:ProjectName"] a')
            item_name = name_element.text.strip() if name_element else "N/A"
            
            creator_element = card.find('span', class_='_tc--lighter', string=lambda t: t and 'by' in t)
            creator_name = creator_element.text.strip().replace('by ', '') if creator_element else "N/A"
            
            funds_element = card.select_one('[data-qa="project-card:FundsGathered"]')
            funds_gathered = funds_element.text.strip() if funds_element else "N/A"
            
            extracted_data.append({
                "å•†å“å": item_name,
                "è²©å£²å…ƒ": creator_name,
                "é‡‘é¡": funds_gathered,
            })
        return extracted_data

    # --- ä¿å­˜å‡¦ç†ã‚’ä¿®æ­£ ---
    def process_and_save(self, projects):
        """æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›ã—ã€æ—¥ä»˜ä»˜ãã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
        df = pd.DataFrame(projects)
        
        # å®Ÿè¡Œæ—¥ã®å–å¾—ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ (indiegogo_YYYYMMDD.csv)
        today_str = datetime.datetime.now().strftime("%Y%m%d")
        dynamic_output_file = f"indiegogo_{today_str}.csv"
        
        # CSVã¨ã—ã¦ä¿å­˜
        df.to_csv(dynamic_output_file, index=False, encoding='utf-8-sig') 
        
        self.update_status(f" ãƒ‡ãƒ¼ã‚¿ã¯æ­£å¸¸ã« {dynamic_output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚åˆè¨ˆ {len(df)} ä»¶ã€‚")


if __name__ == "__main__":
    app = ScraperApp()
    app.mainloop()